# Volatility
# Copyright (C) 2007-2013 Volatility Foundation
# Copyright (c) 2008 Brendan Dolan-Gavitt <bdolangavitt@wesleyan.edu>
#
# Additional Authors:
# Mike Auty <mike.auty@gmail.com>
#
# This file is part of Volatility.
#
# Volatility is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 2 of the License, or
# (at your option) any later version.
#
# Volatility is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with Volatility.  If not, see <http://www.gnu.org/licenses/>.
#
import copy
import hashlib
import json
import logging
import ntpath
import os
import re
import shutil
import time
from StringIO import StringIO
from collections import defaultdict
from datetime import datetime
from urlparse import urljoin

import requests
import tenacity

from volatility.plugins import imageinfo
from volatility.plugins import taskmods
from volatility.plugins.cmdline import Cmdline
from volatility.plugins.dlldump import DLLDump
from volatility.plugins.envars import Envars
from volatility.plugins.malware.malfind import Malfind
from volatility.plugins.procdump import ProcDump
from volatility.plugins.taskmods import DllList

VERSION = '1.0.0'

logger = logging.getLogger('')
logger.setLevel(logging.DEBUG)
fh = logging.FileHandler('analyze.log')
formatter = logging.Formatter('[%(asctime)s] - %(funcName)s - %(message)s',
                              datefmt='%a, %d %b %Y %H:%M:%S')
fh.setFormatter(formatter)
logger.addHandler(fh)

API_VERSION = 'v2-0'

MESSAGES = {
    'missing_api_key': 'Please set INTEZER_API_KEY in your environment variables or API KEY (--API_KEY)',
    'authentication_failure': 'Failed to authenticate Intezer service',
    'insufficient_quota': 'You have reached your daily quota. Please contact support@intezer.com to discuss your plan options',
    'no files extracted': 'No files were extracted, aborting'
}

END_REASONS = {
    'DONE': 'done',
    'INTERRUPTED': 'interrupted',
    'FAILED': 'failed'
}

DUMP_TYPES = {
    'PROC_DUMP': 'proc_dump',
    'DLL': 'dll',
    'MALFIND': 'malfind'
}

FILE_TYPES = {
    'EXECUTABLE': 'executable',
    'MODULE': 'module',
    'MALFIND': 'malfind'
}

MALFIND_DIR = 'malfind'
SCAN_TYPE_MEMORY_DUMP_ANALYSIS = 'memory_dump_analysis'


def path_leaf(path):
    head, tail = ntpath.split(path)
    return tail or ntpath.basename(head)


def run_volatility_command_and_get_info(config, plugin_class):
    str_io = StringIO()
    plugin = plugin_class(copy.deepcopy(config))
    plugin.render_json(str_io, plugin.calculate())
    return json.loads(str_io.getvalue())


# Gets the process path, sometimes the process path arrives corrupted with a random quote string, if so we remove it.
# Some arrive with trailing strings we do not need, also removing those.
def normalize_process_path(process_path):
    if not process_path:
        return ''

    if process_path[0] == '"':
        process_path = process_path[1:]

    extension = '.exe'
    extension_index = process_path.find(extension)
    if extension_index != -1:
        return process_path[:extension_index + len(extension)]

    return process_path


def get_image_info(config):
    return run_volatility_command_and_get_info(config, imageinfo.ImageInfo)['rows'][0]


def get_system_type(system_type):
    if system_type == '86':
        system_type = '32'
    if system_type not in ('64', '32'):
        system_type = 'unknown'

    return system_type


def is_fileless(data):
    return data[:2] != 'MZ'


class WrongDumpTypeException(Exception):
    pass


class IntezerProxy:
    def __init__(self, base_url, api_key):
        self.base_url = base_url
        self.api_key = api_key
        self._session = None
        self.scan_id = None

        self.api_url = urljoin(base_url, '/api')
        self.scans_url = urljoin(base_url, '/scans')

        self.urls = {
            'get_access_token': '{}/{}/get-access-token'.format(self.api_url, API_VERSION),
            'start_scan': '{}/scans'.format(self.api_url),
            'set_host_info': '{}/scans/{}/host-info'.format(self.scans_url, '{}'),
            'send_processes_info': '{}/scans/{}/processes-info'.format(self.scans_url, '{}'),
            'send_loaded_modules_info': '{}/scans/{}/processes/{}/loaded-modules-info'.format(self.scans_url, '{}', '{}'),
            'send_memory_module_dumps_info': '{}/scans/{}/memory-module-dumps-info'.format(self.scans_url, '{}'),
            'upload_collected_binaries': '{}/scans/{}/{}/collected-binaries'.format(self.scans_url, '{}', '{}'),
            'end_scan': '{}/scans/{}/end'.format(self.scans_url, '{}'),
        }

    @property
    def session(self):
        if not self._session:
            session = requests.session()
            session.mount('https://', requests.adapters.HTTPAdapter(max_retries=3))
            session.mount('http://', requests.adapters.HTTPAdapter(max_retries=3))
            session.headers = {'User-Agent': 'volatility_plugin/{}'.format(VERSION)}
            self._session = session
        return self._session

    def _init_access_token(self):
        if 'Authorization' not in self.session.headers:
            response = requests.post(self.urls['get_access_token'], json={'api_key': self.api_key})
            if response.status_code == '404':
                logger.error(MESSAGES['authentication_failure'])

            response.raise_for_status()
            token = 'Bearer {}'.format(response.json()['result'])
            self.session.headers['Authorization'] = token

    @tenacity.retry(retry=tenacity.retry_if_exception_type(requests.exceptions.RequestException),
                    stop=tenacity.stop_after_attempt(2))
    def _post(self, url_path, **kwargs):
        self._init_access_token()
        return self.session.post(url_path, **kwargs)

    def start_scan(self, host_info):
        data = {'start_time': time.time(),
                'scanner_info': host_info,
                'options': {'analyze': True},
                'scan_type': SCAN_TYPE_MEMORY_DUMP_ANALYSIS}

        response = self._post(self.urls['start_scan'], json=data)
        if response.status_code == '403':
            logger.error(MESSAGES['insufficient_quota'])
        response.raise_for_status()

        self.scan_id = response.json()['result']['scan_id']

    def send_host_info(self, system_type, profile, computer_name):
        host_info = {'host_info': {'system_type': system_type,
                                   'profile': profile,
                                   'computer_name': computer_name}
                     }
        response = self._post(self.urls['set_host_info'].format(self.scan_id), json=host_info)
        response.raise_for_status()

    def send_processes_info(self, ps_list):
        response = self._post(self.urls['send_processes_info'].format(self.scan_id), json={'processes_info': ps_list})
        response.raise_for_status()

    def send_loaded_modules_info(self, pid, loaded_modules_list):
        response = self._post(self.urls['send_loaded_modules_info'].format(self.scan_id, pid),
                              json={'loaded_modules_info': loaded_modules_list})
        response.raise_for_status()

    def send_memory_module_dumps_info(self, memory_modules_info):
        response = self._post(self.urls['send_memory_module_dumps_info'].format(self.scan_id),
                              json={'memory_module_dumps_info': memory_modules_info})
        response.raise_for_status()
        return response.json()['result']

    def upload_collected_binaries(self, dump_file_path, collected_from):
        with open(dump_file_path, 'rb') as file_to_upload:
            response = self._post(self.urls['upload_collected_binaries'].format(self.scan_id, collected_from),
                                  headers={'Content-Type': 'application/octet-stream'},
                                  data=file_to_upload)
            response.raise_for_status()

    def end_scan(self, end_reason):
        response = self._post(self.urls['end_scan'].format(self.scan_id),
                              json={'end_time': time.time(), 'reason': end_reason})
        response.raise_for_status()


class Intezer(ProcDump):
    "Intezer memory dump"

    def __init__(self, config, *args, **kwargs):
        self.image_info = get_image_info(config)
        ProcDump.__init__(self, config, *args, **kwargs)
        config.add_option('API-KEY',
                          short_option='z',
                          default=None,
                          action='store',
                          type='string',
                          help='Intezer API KEY')
        config.add_option('BASE-URL',
                          default='https://analyze.intezer.com',
                          action='store',
                          type='string',
                          help='Intezer Base Url')
        config.add_option('SET-PROFILE',
                          short_option='y',
                          default=str(self.image_info[0]).split(',')[0],
                          action='store',
                          type='string',
                          help='Set Profile')
        config.UNSAFE = True
        config.PROFILE = config.SET_PROFILE
        config.DUMP_DIR = os.path.join(os.getcwd(), 'tmp')
        if not os.path.exists(config.DUMP_DIR):
            os.makedirs(config.DUMP_DIR)
        self.api_key = os.getenv('INTEZER_API_KEY') or config.API_KEY
        self.proxy = IntezerProxy(config.BASE_URL, self.api_key)
        self.dump_info_list = list()
        self.dump_file_path_by_sha256 = dict()
        self.fileless_dump_file_path_by_sha256 = dict()
        self.process_path_by_pid = dict()
        self.username_by_pid = dict()
        self.path_by_dll_name = dict()
        self.computer_name = None
        self.username = None
        self.system_type = None
        self.end_reason = END_REASONS['DONE']

    def get_host_info(self):
        host_info = dict()
        workdir_info = self.image_info[2]
        process_path = str(workdir_info[workdir_info.find("(") + 1:workdir_info.find(")")])
        host_info['process_path'] = process_path
        host_info['workdir'] = process_path[:(process_path.rfind('/') + 1)]
        self.system_type = (get_system_type(self._config.PROFILE.split('_')[0][-2:]))
        host_info['image_type'] = self.system_type
        host_info['username'] = self.username

        return host_info

    def load_env_vars_info(self):
        env_vars = run_volatility_command_and_get_info(self._config, Envars)['rows']
        for env_row in env_vars:
            if str(env_row[3]) == 'COMPUTERNAME':
                self.computer_name = str(env_row[4])
            elif str(env_row[3]) == 'USERNAME':
                self.username_by_pid[int(env_row[0])] = str((env_row[4]))

        self.username = self.username_by_pid.values()[0]

    def load_dump_modules_info(self, dumps, dump_type):
        for dump in dumps:
            file_name, dump_file_path = self.get_name_and_dump_path_by_dump_and_type(dump, dump_type)
            if not file_name:
                continue

            pid = self.get_pid_by_dump_type_and_file_name(dump, dump_type, file_name)
            base_address = self.get_base_address_by_dump_and_type(dump, dump_type)
            file_path = self.get_file_path_by_type_and_pid(dump, dump_type, pid)

            dump_info = dict(pid=pid, base_address=base_address, file_path=file_path, dump_file_path=dump_file_path)
            self.dump_info_list.append(dump_info)

    def get_name_and_dump_path_by_dump_and_type(self, dump, dump_type):
        file_name = None
        dump_dir = self._config.DUMP_DIR
        if dump_type in (DUMP_TYPES['PROC_DUMP'], DUMP_TYPES['DLL']):
            if dump_type == DUMP_TYPES['PROC_DUMP']:
                file_name = str(dump[3])
            else:
                file_name = str(dump[4])

            if 'Error:' in file_name:
                logger.warning(dump)
                return None, None

            file_name = file_name[4:]
        else:
            dump_dir = os.path.join(self._config.DUMP_DIR, MALFIND_DIR)
            for cur_file in os.listdir(dump_dir):
                if cur_file.endswith('.{0:#x}.dmp'.format(dump[2])):
                    file_name = cur_file
                    break

        return file_name, os.path.join(dump_dir, file_name)

    @staticmethod
    def get_pid_by_dump_type_and_file_name(dump, dump_type, file_name):
        if dump_type == DUMP_TYPES['MALFIND']:
            return dump[1]
        elif dump_type == DUMP_TYPES['PROC_DUMP']:
            # The pid is in the output file's name.
            executable = re.search('executable.(.*).', file_name)
            return int(executable.group(1).split('.')[0])

        elif dump_type == DUMP_TYPES['DLL']:
            # The pid is in the output file's name.
            module = re.search('module.(.*).', file_name)
            return int(module.group(1).split('.')[0])

        raise WrongDumpTypeException()

    @staticmethod
    def get_base_address_by_dump_and_type(dump, dump_type):
        if dump_type == DUMP_TYPES['PROC_DUMP']:
            return dump[0]
        elif dump_type == DUMP_TYPES['DLL']:
            return dump[2]
        elif dump_type == DUMP_TYPES['MALFIND']:
            return dump[2]

        raise WrongDumpTypeException()

    def get_file_path_by_type_and_pid(self, dump, dump_type, pid):
        if dump_type == DUMP_TYPES['PROC_DUMP']:
            return self.process_path_by_pid[pid]
        elif dump_type == DUMP_TYPES['DLL']:
            dll_name = str(dump[3])
            if dll_name in self.path_by_dll_name:
                return self.path_by_dll_name[dll_name]
            else:
                return self.process_path_by_pid[pid]
        elif dump_type == DUMP_TYPES['MALFIND']:
            return str(dump[0])

        raise WrongDumpTypeException()


    # While we are going over all the files extracted (mostly the dlls), we will have a lot of duplicate files in different processes and paths.
    # In order to reduce the amount of files we send, we are 'merging' the files which have identical headers.
    # What exactly is this 'merging'?
    # Lets say we have file x and file y, both with the same header, but different processes and file_paths and different files the were dumped.
    # we will send the full information on both files, but instead of uploading both file X and file Y,
    # we will only upload file X.
    # This greatly reduces the amount of files we send to analyze and makes the whole process faster.
    def merge_and_enrich_dumps(self):
        header_hash_set = set()
        sha256_by_header_hash = dict()
        for dump_info in self.dump_info_list:
            dump_file_path = dump_info['dump_file_path']
            with open(dump_file_path, 'r') as f:
                data = f.read()
                header_hash = hashlib.sha256(data[:0x400]).hexdigest()
                fileless = is_fileless(data)
                if header_hash not in header_hash_set:
                    header_hash_set.add(header_hash)
                    sha256 = hashlib.sha256(data).hexdigest()
                    sha256_by_header_hash[header_hash] = sha256
                    self.dump_file_path_by_sha256[sha256] = dump_file_path
                    if fileless:
                        self.fileless_dump_file_path_by_sha256[sha256] = dump_file_path

                dump_info['sha256'] = sha256_by_header_hash[header_hash]
                dump_info['is_fileless'] = fileless
                dump_info['size'] = os.stat(dump_file_path).st_size

    def get_loaded_modules_info(self):
        loaded_modules_info = defaultdict(list)
        for dump_info in self.dump_info_list:
            pid = dump_info['pid']
            loaded_module_info = dict(image_type=self.system_type,
                                      base_address=dump_info['base_address'],
                                      mapped_size_in_bytes=dump_info['size'],
                                      file_path=dump_info['file_path'])
            loaded_modules_info[pid].append(loaded_module_info)
        return loaded_modules_info

    def get_memory_dumps_info(self):
        memory_dumps_info = list()
        for dump_info in self.dump_info_list:
            memory_dump_info = dict(base_address=dump_info['base_address'],
                                    pid=dump_info['pid'],
                                    sha256=dump_info['sha256'])

            if dump_info['is_fileless']:
                memory_dump_info['is_fileless'] = True
            memory_dumps_info.append(memory_dump_info)

        return memory_dumps_info

    # DLLDump doesn't get all the dll paths, so we use this to build dll_path dict.
    def load_dll_paths(self):
        dll_list = run_volatility_command_and_get_info(self._config, DllList)['rows']

        for dll in dll_list:
            dll_path = str(dll[5])
            dll_name = path_leaf(dll_path)
            self.path_by_dll_name[dll_name] = dll_path

    def get_ps_list(self, config):
        process_list = run_volatility_command_and_get_info(config, taskmods.PSList)
        cmd_lines = run_volatility_command_and_get_info(config, Cmdline)
        ps_list = list()

        for cmd_line in cmd_lines['rows']:
            self.process_path_by_pid[int(cmd_line[1])] = normalize_process_path(str(cmd_line[2]))

        for cur_process in process_list['rows']:
            cur_process_time = (str(cur_process[8]))[:-9]
            start_timestamp = time.time()
            if cur_process_time:
                start_timestamp = time.mktime(datetime.strptime(cur_process_time, '%Y-%m-%d %H:%M:%S').timetuple())
            pid = int(cur_process[2])
            user_name = self.username_by_pid.get(pid, self.username)
            ps = dict(pid=pid,
                      ppid=int(cur_process[3]),
                      process_path=self.process_path_by_pid[pid],
                      start_time=start_timestamp,
                      username=user_name)
            ps_list.append(ps)

        return ps_list

    def verify_params(self):
        if not self.api_key:
            logger.error(MESSAGES['missing_api_key'])
            return False

        if not self._config.DUMP_DIR:
            logger.error("Please specify an Dump Directory (-D)")
            return False
        return True

    def load_dump_modules(self):
        proc_dumps = run_volatility_command_and_get_info(self._config, ProcDump)['rows']
        self.load_dump_modules_info(proc_dumps, DUMP_TYPES['PROC_DUMP'])

        self.load_dll_paths()
        dll_dumps = run_volatility_command_and_get_info(self._config, DLLDump)['rows']
        self.load_dump_modules_info(dll_dumps, DUMP_TYPES['DLL'])

        config = copy.deepcopy(self._config)
        config.DUMP_DIR = os.path.join(config.DUMP_DIR, MALFIND_DIR)
        if not os.path.exists(config.DUMP_DIR):
            os.makedirs(config.DUMP_DIR)

        malfind_dumps = run_volatility_command_and_get_info(config, Malfind)['rows']
        self.load_dump_modules_info(malfind_dumps, DUMP_TYPES['MALFIND'])

        self.merge_and_enrich_dumps()

    def execute(self):
        if not self.verify_params():
            return

        self.load_env_vars_info()
        start_scan_info = self.get_host_info()
        ps_list = self.get_ps_list(self._config)
        self.load_dump_modules()

        loaded_modules_info = self.get_loaded_modules_info()
        memory_dumps_info = self.get_memory_dumps_info()

        if not (len(loaded_modules_info) or len(memory_dumps_info)):
            logger.error(MESSAGES['no files extracted'])
            return

        try:
            self.proxy.start_scan(start_scan_info)

            self.proxy.send_host_info(self.system_type, self._config.PROFILE, self.computer_name)

            self.proxy.send_processes_info(ps_list)

            for pid, loaded_modules_list in loaded_modules_info.items():
                if loaded_modules_list:
                    self.proxy.send_loaded_modules_info(pid, loaded_modules_list)

            files_to_upload = set(self.proxy.send_memory_module_dumps_info(memory_dumps_info))
            fileless_files = set(self.fileless_dump_file_path_by_sha256.keys())
            fileless_files_to_upload = files_to_upload.intersection(fileless_files)
            files_to_upload = files_to_upload - fileless_files_to_upload

            if files_to_upload:
                for sha256 in files_to_upload:
                    sha256 = str(sha256)
                    self.proxy.upload_collected_binaries(self.dump_file_path_by_sha256[sha256], 'memory')
            if fileless_files_to_upload:
                for sha256 in fileless_files_to_upload:
                    sha256 = str(sha256)
                    self.proxy.upload_collected_binaries(self.dump_file_path_by_sha256[sha256], 'fileless')

        except KeyboardInterrupt:
            self.end_reason = END_REASONS['INTERRUPTED']

        except Exception as e:
            logger.error(e)
            self.end_reason = END_REASONS['FAILED']

        finally:
            self.proxy.end_scan(self.end_reason)
            shutil.rmtree(self._config.DUMP_DIR)
            os.makedirs(self._config.DUMP_DIR)
